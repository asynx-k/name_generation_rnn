{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908834a3-d7b0-4fd1-938a-5abcb3c87857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import Unigram\n",
    "from tokenizers.normalizers import Lowercase\n",
    "from tokenizers.trainers import UnigramTrainer\n",
    "from tokenizers.processors import TemplateProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab3e8b4-bb75-46b2-a0cf-37fd1623792b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae4488-57d3-4b35-a939-4e882206e2d0",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82b1adc-79ee-43ce-a454-e56d0b6b65fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>имя</th>\n",
       "      <th>язык</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acapella</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Achilles</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adriana</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpha</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alyssum</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>Ярика</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>Яриска</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Ярка</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>Яркиса</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>Ярыся</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2913 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           имя язык\n",
       "0     Acapella   en\n",
       "1     Achilles   en\n",
       "2      Adriana   en\n",
       "3        Alpha   en\n",
       "4      Alyssum   en\n",
       "...        ...  ...\n",
       "2908     Ярика  rus\n",
       "2909    Яриска  rus\n",
       "2910      Ярка  rus\n",
       "2911    Яркиса  rus\n",
       "2912     Ярыся  rus\n",
       "\n",
       "[2913 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/pets_ru_en.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640b3e1e-8510-4a9c-9dd3-c5287a444e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = data.имя.str.len().max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959a978f-16f4-4346-a464-957322a2bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unigram()\n",
    "tokenizer = Tokenizer(model)\n",
    "tokenizer.normalizer = Lowercase()\n",
    "tokenizer.post_processor = TemplateProcessing('$0 <EOS>', special_tokens=[(\"<EOS>\", 3)])\n",
    "\n",
    "tokenizer.enable_padding(direction='right', pad_id=0, pad_token='<PAD>', max_length=22)\n",
    "tokenizer.enable_truncation(max_length=22)\n",
    "\n",
    "trainer = UnigramTrainer(special_tokens=['<PAD>', '<SOS>', '<UNK>', '<EOS>', '<RU>', '<EN>'], \n",
    "                         unk_token='<UNK>', pad_token='<PAD>', max_piece_length=1)\n",
    "\n",
    "tokenizer.train_from_iterator(data.имя, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc2a537-e82e-43f9-9b15-2f6fd6b042a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d4a9d1-1f76-461b-8bb7-ca522ea192e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 64,\n",
       " 'п': 39,\n",
       " 'w': 54,\n",
       " 'с': 11,\n",
       " 'у': 28,\n",
       " '-': 62,\n",
       " 'ы': 59,\n",
       " 'z': 57,\n",
       " 'j': 61,\n",
       " 'т': 22,\n",
       " 'й': 50,\n",
       " '<UNK>': 2,\n",
       " 'y': 38,\n",
       " 'i': 17,\n",
       " 'н': 13,\n",
       " 'э': 42,\n",
       " 's': 20,\n",
       " '<SOS>': 1,\n",
       " 'a': 9,\n",
       " 'h': 34,\n",
       " 'ц': 56,\n",
       " 'g': 41,\n",
       " 'k': 48,\n",
       " 'р': 16,\n",
       " 'а': 6,\n",
       " 'м': 26,\n",
       " 'b': 36,\n",
       " 'л': 10,\n",
       " '<EN>': 5,\n",
       " 'ш': 31,\n",
       " 'ф': 37,\n",
       " 'ж': 51,\n",
       " 'u': 29,\n",
       " 'x': 58,\n",
       " 'к': 14,\n",
       " 'n': 19,\n",
       " ' ': 60,\n",
       " 'c': 27,\n",
       " 'f': 46,\n",
       " 'ю': 53,\n",
       " '<PAD>': 0,\n",
       " 'и': 7,\n",
       " '<RU>': 4,\n",
       " 'o': 18,\n",
       " 'з': 44,\n",
       " 'б': 43,\n",
       " 't': 23,\n",
       " 'd': 33,\n",
       " 'в': 45,\n",
       " 'r': 12,\n",
       " 'х': 52,\n",
       " 'p': 30,\n",
       " 'ё': 63,\n",
       " 'щ': 65,\n",
       " 'я': 25,\n",
       " 'д': 35,\n",
       " 'e': 8,\n",
       " '<EOS>': 3,\n",
       " 'v': 55,\n",
       " 'l': 21,\n",
       " 'm': 32,\n",
       " 'ь': 40,\n",
       " 'ч': 49,\n",
       " 'о': 24,\n",
       " 'е': 15,\n",
       " 'г': 47}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65da62-19c4-4eec-8a5b-6f8368ea59d0",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b9e643-2bf7-40ce-80d1-8c3e1b4de01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameGenDataset():\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, lang = self.data.iloc[idx]\n",
    "        x = torch.tensor(self.tokenizer.encode(x).ids)[:-1]\n",
    "        x = torch.cat((torch.tensor([4 if lang == 'rus' else 5]), x))\n",
    "        y = torch.cat((x[1:], torch.tensor([0])))\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e35fd2-aaea-4ad3-8302-aa8cf2929d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NameGenDataset(data, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a80b25c-4bda-4f79-bd5f-dd70ed62bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 22]), torch.Size([128, 22]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7cb9fad-a857-4612-9486-6ca3bd9bcc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 20, 18,  ...,  0,  0,  0],\n",
       "        [ 5, 32,  9,  ...,  0,  0,  0],\n",
       "        [ 4, 24, 37,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 5, 27, 12,  ...,  0,  0,  0],\n",
       "        [ 4, 25, 13,  ...,  0,  0,  0],\n",
       "        [ 4, 37,  6,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd18223-b83a-492f-9140-30a5cbe5196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 18, 27,  ...,  0,  0,  0],\n",
       "        [32,  9, 32,  ...,  0,  0,  0],\n",
       "        [24, 37,  7,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [27, 12, 29,  ...,  0,  0,  0],\n",
       "        [25, 13, 25,  ...,  0,  0,  0],\n",
       "        [37,  6, 13,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a2f0c-6997-4584-b0f9-d5f14a5bb8fd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2820f88c-6d0e-4bb5-863d-c341764ce253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, dataloader, loss, optimizer, verbose=False):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for ind, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        pred_logits, h = model(X)\n",
    "        batch_loss = loss(pred_logits, y.flatten())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += batch_loss.item()\n",
    "\n",
    "        if verbose and ind % verbose == 0:\n",
    "            print(f'Loss: {round(batch_loss.item(), 5)}')\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Train Loss: {round(epoch_loss, 5)}\\n')\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b526e973-b559-432a-9a70-e10d8747faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, X, h=None):\n",
    "        emb_X = self.embedding(X)\n",
    "        out, h = self.gru(emb_X, h)\n",
    "        out = out.flatten(0, 1)\n",
    "        logits = self.classifier(out)\n",
    "\n",
    "        return logits, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606d3b0-c9f4-4252-adaa-1eac850b839a",
   "metadata": {},
   "source": [
    "# Name Generation and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0643835-dd8c-4afc-b57e-0e5d15b10cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(model, first_token='<RU>', max_len=22, ignore_context=False):\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    \n",
    "    sequence = [tokenizer.token_to_id(first_token)]\n",
    "    h = None\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, max_len + 1):\n",
    "            input_seq = torch.tensor([sequence[i-1]]).unsqueeze(0)\n",
    "            \n",
    "            pred_logits, h = model(input_seq, h)\n",
    "            pred_logits = pred_logits.softmax(1)[-1].flatten()\n",
    "            \n",
    "            next_letter = torch.multinomial(pred_logits, 1)\n",
    "\n",
    "            if next_letter == 3:\n",
    "                break\n",
    "\n",
    "            sequence.append(next_letter)\n",
    "\n",
    "    sequence = tokenizer.decode(sequence).replace(' ', '')\n",
    "    model.to(DEVICE)\n",
    "    return ''.join(sequence).title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb1706de-9712-494c-82d1-f1c015560337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(tokenizer.get_vocab_size(), 200, 128).to(DEVICE)\n",
    "loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "lr = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "n_epochs = 60\n",
    "print_every = 20\n",
    "verbose_every = 10\n",
    "verbose = False\n",
    "\n",
    "model_weights_path = 'model_weights.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfc6177b-c8f8-4646-99db-abb50ae604b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "---------------\n",
      "Loss: 4.21957\n",
      "Loss: 2.47712\n",
      "Loss: 2.43744\n",
      "Train Loss: 2.67618\n",
      "\n",
      "Generated <RU> Names:\n",
      "1 - Розаррика\n",
      "2 - Цейза\n",
      "3 - Моняда\n",
      "Generated <EN> Names:\n",
      "1 - Ganflichern\n",
      "2 - Kandanntpe\n",
      "3 - Banlermannro\n",
      "\n",
      "EPOCH 20\n",
      "---------------\n",
      "Loss: 1.43492\n",
      "Loss: 1.51585\n",
      "Loss: 1.55633\n",
      "Train Loss: 1.50704\n",
      "\n",
      "Generated <RU> Names:\n",
      "1 - Элизма\n",
      "2 - Чоша\n",
      "3 - Джсефи\n",
      "Generated <EN> Names:\n",
      "1 - Tiny\n",
      "2 - Chinmer\n",
      "3 - Nytman\n",
      "\n",
      "EPOCH 40\n",
      "---------------\n",
      "Loss: 1.30118\n",
      "Loss: 1.30806\n",
      "Loss: 1.38868\n",
      "Train Loss: 1.32585\n",
      "\n",
      "Generated <RU> Names:\n",
      "1 - Люсик\n",
      "2 - Жесика\n",
      "3 - Гатэн\n",
      "Generated <EN> Names:\n",
      "1 - Pal\n",
      "2 - Tоockle\n",
      "3 - Seal\n",
      "\n",
      "EPOCH 60\n",
      "---------------\n",
      "Loss: 1.21899\n",
      "Loss: 1.28072\n",
      "Loss: 1.31083\n",
      "Train Loss: 1.27748\n",
      "\n",
      "Generated <RU> Names:\n",
      "1 - Царья\n",
      "2 - Зетти\n",
      "3 - Расума\n",
      "Generated <EN> Names:\n",
      "1 - Cato\n",
      "2 - Bambi\n",
      "3 - Puff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs + 1):\n",
    "    if epoch % print_every == 0:\n",
    "        print(f'EPOCH {epoch}\\n---------------')\n",
    "        verbose = 10\n",
    "    else:\n",
    "        verbose = False\n",
    "\n",
    "    train_loss = train_loop(model, dataloader, loss, optimizer, verbose)\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        for lang in ['<RU>', '<EN>']:\n",
    "            names = [generate_name(model, lang) for i in range(3)]\n",
    "            print(f'Generated {lang} Names:')\n",
    "            for ind, name in enumerate(names):\n",
    "                print(f'{ind + 1} - {name}')\n",
    "        \n",
    "        print()\n",
    "\n",
    "torch.save(model.state_dict(), model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7572d5-24ca-41b7-a2c8-db1698cbc52c",
   "metadata": {},
   "source": [
    "# Name Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8320cf6f-8b64-4319-bd8a-50521e0daedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(tokenizer.get_vocab_size(), 200, 128).to(DEVICE)\n",
    "model.load_state_dict(torch.load(model_weights_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23cdeea8-3787-42b7-88e6-5e68284668a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated <RU> Names:\n",
      "1 - Санни\n",
      "2 - Персида\n",
      "3 - Пумка\n",
      "4 - Темантея\n",
      "5 - Дери\n",
      "6 - Ханда\n",
      "7 - Русалка\n",
      "8 - Джеси\n",
      "9 - Тапана\n",
      "10 - Рыжинка\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "lang = '<RU>'\n",
    "\n",
    "names = [generate_name(model, lang) for i in range(n)]\n",
    "    \n",
    "print(f'Generated {lang} Names:')\n",
    "for ind, name in enumerate(names):\n",
    "    print(f'{ind + 1} - {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e2cb022-a27e-41bc-beba-ffe6e2b19a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated <EN> Names:\n",
      "1 - Deesycaio\n",
      "2 - Darlos\n",
      "3 - Oscar\n",
      "4 - Sesame\n",
      "5 - Shaggy\n",
      "6 - Chrystal\n",
      "7 - Roаfaffer\n",
      "8 - Khenelau\n",
      "9 - Bling\n",
      "10 - Qearma\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "lang = '<EN>'\n",
    "\n",
    "names = [generate_name(model, lang) for i in range(n)]\n",
    "    \n",
    "print(f'Generated {lang} Names:')\n",
    "for ind, name in enumerate(names):\n",
    "    print(f'{ind + 1} - {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376457a-f2e3-4763-9099-002813d53563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
